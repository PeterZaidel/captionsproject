{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import MSCOCODataset\n",
    "from torch.optim import lr_scheduler\n",
    "from autocorrect import spell\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_SEND = '<SEND>'\n",
    "DEF_START = '<START>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATSET_FILE = 'traindataset_cnn_vgg.tar.gz'\n",
    "TEST_DATSET_FILE = 'testdataset_cnn_vgg.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/home/p.zaydel/ProjectNeuralNets/coco_dataset/'\n",
    "imagesDirTrain = '{}train2017/train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017/val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}/annotations_trainval2017/annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}/annotations_trainval2017/annotations/captions_val2017.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.Compose([\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                           ])\n",
    "transform_to224 = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transform_tensor\n",
    "                                     ])\n",
    "transform_to500 = transforms.Compose([ transforms.Resize((500, 500)),\n",
    "                                      transform_tensor\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_text2words(text):\n",
    "    symbs_to_replace = ['.', ',', '/', '-', ':', '{', '}', '[', ']', ]\n",
    "    for smb in symbs_to_replace:\n",
    "        text = text.replace(smb, ' ')\n",
    "    \n",
    "    \n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    for idx in range(len(words)):\n",
    "        words[idx] = spell(words[idx])\n",
    "    \n",
    "    words = [DEF_START] + words + [DEF_SEND]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# def anns2words(anns_list):\n",
    "#     texts = []\n",
    "#     for anns in anns_list:\n",
    "#         for ann in anns['anns']:\n",
    "#             words = split_text2words(ann)\n",
    "#             texts.append(words)\n",
    "            \n",
    "#     return texts\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "def train_word_to_vec_gensim(dataset, embed_size = 300):\n",
    "    Texts = dataset.anns.values()\n",
    "    model = Word2Vec(Texts, size = embed_size)\n",
    "    return model\n",
    "\n",
    "def generate_vocab_dicts(dataset): \n",
    "    Texts = dataset.anns.values()\n",
    "    uniqwords = list(set([w for ann in Texts for w in ann]))\n",
    "    words2ids = dict(zip(uniqwords, range(len(uniqwords))) )\n",
    "    ids2words = dict(zip(range(len(uniqwords)), uniqwords ))\n",
    "    return words2ids, ids2words\n",
    "\n",
    "\n",
    "def wordslist2wordids(words, word2id, vector_length = None ):\n",
    "    if vector_length is None:\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))\n",
    "\n",
    "\n",
    "def sentence2wordids(sentence, word2id, vector_length = None):\n",
    "    \n",
    "    if vector_length is None:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))         \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "# calculates dimension of alexnet convolutions layers output \n",
    "def get_alexnet_features_dim(imsize):\n",
    "    adim = int(np.round( 3*0.01*imsize - 1))\n",
    "    return 1*256*adim*adim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_dataset(dataset, filename, cnn_model = models.alexnet(pretrained=True).features):\n",
    "    \n",
    "    cnn_model = cnn_model.cuda(gpu_device)\n",
    "    \n",
    "    print(\"preparing images...\")\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        sample = dataset[idx]\n",
    "        var = Variable(sample['image'].unsqueeze(0)).cuda(gpu_device)\n",
    "        dataset.images_cnn[idx] =  cnn_model(var).data.view(-1).cpu()\n",
    "        \n",
    "    print(\"preparing annotations...\")\n",
    "    dataset.text_transform = split_text2words\n",
    "    dataset.preload_anotations()\n",
    "    dataset.text_transform = None\n",
    "    \n",
    "    torch.save(dataset, filename)\n",
    "    print(\"Dataset saved in {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anns(dataset, annids, max_len, prepare = None):\n",
    "    '''\n",
    "       dataset - MSCOCODataset\n",
    "       annids -  tensor or numpy array\n",
    "       max_len - maximum len of sentence. If None computes from dataset \n",
    "       prepare - None or function to prepare each word, returns 1-dim tensor\n",
    "       \n",
    "       return Pytorch Tensor [len(annids) x max_sentence_len x prepare(word).shape[0] ]\n",
    "    '''\n",
    "    result = []\n",
    "    \n",
    "    if prepare is None:\n",
    "        prepare = lambda w: word_embeding[w]\n",
    "    \n",
    "    for i in range(annids.shape[0]):\n",
    "        words = dataset.get_ann(annids[i])\n",
    "        ann_res = []\n",
    "        \n",
    "        for idx in range(max_len):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = DEF_SEND\n",
    "                \n",
    "            ann_res.append(prepare(w))\n",
    "        ann_res = torch.from_numpy(np.array(ann_res)).float()\n",
    "        result.append(ann_res)\n",
    "        \n",
    "    return torch.stack(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary......\n",
      "loading dictionary\n",
      "dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Creating dictionary......\")\n",
    "if os.path.exists('dictionaries.tar.gz'):\n",
    "    print(\"loading dictionary\")\n",
    "    dic_state = torch.load('dictionaries.tar.gz')\n",
    "    words2ids = dic_state['words2ids']\n",
    "    ids2words = dic_state['ids2words']\n",
    "    print(\"dictionary loaded\")\n",
    "else:\n",
    "    words2ids, ids2words  = generate_vocab_dicts(trainDataset)\n",
    "    print(\"saving dictionary\")\n",
    "    torch.save({'words2ids': words2ids, 'ids2words': ids2words }, 'dictionaries.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading words embedding\n",
      "words embedding loaded\n"
     ]
    }
   ],
   "source": [
    "# MY WORD EMBEDDINGS\n",
    "import os\n",
    "\n",
    "WORD_EMBED_FILE = 'word_embeding.tar.gz'\n",
    "if os.path.exists(WORD_EMBED_FILE):\n",
    "    print(\"loading words embedding\")\n",
    "    word_embeding = torch.load(WORD_EMBED_FILE)\n",
    "    print(\"words embedding loaded\")\n",
    "else:\n",
    "    print(\"creating words embedding......\")\n",
    "    word_embeding = train_word_to_vec_gensim(trainDataset, embed_size = 300 )\n",
    "    print(\"saving words embedding\")\n",
    "    torch.save(word_embeding, WORD_EMBED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = models.vgg16(pretrained=True).features\n",
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train dataset...\n",
      "train dataset loaded!\n",
      "loading test dataset...\n",
      "test dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(TRAIN_DATSET_FILE):\n",
    "    print(\"loading train dataset...\")\n",
    "    trainDataset = torch.load(TRAIN_DATSET_FILE)\n",
    "    print('train dataset loaded!')\n",
    "else:\n",
    "    trainDataset = MSCOCODataset(annTrainFile,imagesDirTrain, transform = transform_to224, mode='pic2rand')\n",
    "    save_prepared_dataset(trainDataset, TRAIN_DATSET_FILE, cnn_model)\n",
    "    \n",
    "if os.path.exists(TEST_DATSET_FILE):\n",
    "    print(\"loading test dataset...\")\n",
    "    testDataset = torch.load(TEST_DATSET_FILE)\n",
    "    print('test dataset loaded!')\n",
    "else:\n",
    "    testDataset = MSCOCODataset(annValFile,imagesDirVal, transform = transform_to224, mode='pic2rand')\n",
    "    save_prepared_dataset(testDataset, TEST_DATSET_FILE, cnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack([trainDataset[100]['image'][0].numpy(), \n",
    "#              trainDataset[100]['image'][0].numpy(), \n",
    "#              trainDataset[100]['image'][0].numpy() ]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable(trainDataset[101]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDataset[101]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = cnn_model.cuda(gpu_device)\n",
    "# var = Variable(trainDataset[0]['image'].unsqueeze(0)).cuda(gpu_device)\n",
    "# cnn_model(var).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
