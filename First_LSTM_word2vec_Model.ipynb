{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import MSCOCODataset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import nltk\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f6e025732891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer_ft' is not defined"
     ]
    }
   ],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/home/p.zaydel/ProjectNeuralNets/coco_dataset/'\n",
    "imagesDirTrain = '{}train2017/train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017/val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}/annotations_trainval2017/annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}/annotations_trainval2017/annotations/captions_val2017.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.Compose([\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                           ])\n",
    "transform_to224 = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transform_tensor\n",
    "                                     ])\n",
    "transform_to500 = transforms.Compose([ transforms.Resize((500, 500)),\n",
    "                                      transform_tensor\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.89s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "trainDataset = MSCOCODataset(annTrainFile,imagesDirTrain, transform = transform_to500, mode='pic2rand')\n",
    "testDataset = MSCOCODataset(annValFile,imagesDirVal, transform = transform_to500, mode='pic2rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# print(trainDataset[idx]['anns'])\n",
    "# print(trainDataset[idx]['imid'])\n",
    "# transforms.ToPILImage()(trainDataset[idx]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_SEND = 'SEND'\n",
    "def split_text2words(text, end_word = DEF_SEND):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    if words[-1] == '.':\n",
    "        words.pop(-1)\n",
    "        \n",
    "    words.append(end_word)\n",
    "    return words\n",
    "\n",
    "def anns2words(anns_list, end_word = DEF_SEND):\n",
    "    texts = []\n",
    "    for anns in anns_list:\n",
    "        for ann in anns['anns']:\n",
    "            words = split_text2words(ann, end_word)\n",
    "            texts.append(words)\n",
    "            \n",
    "    return texts\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "def train_word_to_vec_gensim(dataset, embed_size = 4096, end_word = DEF_SEND):\n",
    "    Anns = dataset.get_anns()\n",
    "    Texts = anns2words(Anns, end_word)\n",
    "    model = Word2Vec(Texts, size = embed_size)\n",
    "    return model\n",
    "\n",
    "def generate_vocab_dicts(dataset, end_word = DEF_SEND):\n",
    "    Anns = dataset.get_anns()\n",
    "    Texts = anns2words(Anns, end_word)\n",
    "    uniqwords = list(set([w for ann in Texts for w in ann]))\n",
    "    words2ids = dict(zip(uniqwords, range(len(uniqwords))) )\n",
    "    ids2words = dict(zip(range(len(uniqwords)), uniqwords ))\n",
    "    return words2ids, ids2words\n",
    "\n",
    "def sentence2wordids(sentence, word2id, vector_length = None, end_word = DEF_SEND):\n",
    "    \n",
    "    if vector_length is None:\n",
    "        words = split_text2words(sentence, end_word)\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        words = split_text2words(sentence, end_word)\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[end_word]:\n",
    "            word_ids[-1] = word2id[end_word]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))         \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "# calculates dimension of alexnet convolutions layers output \n",
    "def get_alexnet_features_dim(imsize):\n",
    "    adim = int(np.round( 3*0.01*imsize - 1))\n",
    "    return 1*256*adim*adim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainAnnCaps = [ann['caption'] for ann in trainDataset.coco.loadAnns(trainDataset.coco.getAnnIds())]\n",
    "\n",
    "# trainAnns = trainDataset.get_anns()\n",
    "# trainTexts = anns2words(trainAnns)\n",
    "# sent_lengths = np.array([len(ann) for ann in trainTexts])\n",
    "# print(\"max sent id\", sent_lengths.argmax())\n",
    "# print('max len',np.max(sent_lengths))\n",
    "# plt.plot(np.unique(sent_lengths), np.bincount(sent_lengths)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testAnns = testDataset.get_anns()\n",
    "# testTexts = anns2words(testAnns)\n",
    "# test_sent_lengths = np.array([len(ann) for ann in testTexts])\n",
    "# print(\"max sent id\", test_sent_lengths.argmax())\n",
    "# print('max len',np.max(test_sent_lengths))\n",
    "# test_bin_count = np.bincount(test_sent_lengths)\n",
    "# plt.plot(np.unique(test_sent_lengths), test_bin_count[test_bin_count > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anns = trainDataset.get_anns()\n",
    "# Texts = anns2words(Anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2ids, ids2words  = generate_vocab_dicts(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_embeding = train_word_to_vec_gensim(trainDataset, embed_size = 4096 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sentence2wordids(Anns[0]['anns'][3], words2ids,  vector_length = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = lambda text: sentence2wordids(text, words2ids, vector_length = 20)\n",
    "trainDataset.text_transform = text_transform\n",
    "testDataset.text_transform = text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainDataset, batch_size = 64, shuffle=True)\n",
    "testDataLoader = DataLoader(testDataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in trainDataLoader:\n",
    "#     break\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = word_embeding['.']\n",
    "# print(vec)\n",
    "# word_embeding.wv.similar_by_vector(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(words2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM_W2V_Net(nn.Module):\n",
    "\n",
    "    def __init__(self,  image_size, image_features_size, word_embedding, \n",
    "                 word_embedding_size, words2ids, ids2words,\n",
    "                 \n",
    "                 cnn = models.alexnet(pretrained=True).features, \n",
    "              #   cnn_comp_features = lambda cnn, x: cnn.features(x),\n",
    "                 max_sentence_len = 20,\n",
    "                 sentence_end_embed = None,\n",
    "                 sentence_end_symbol = '.'\n",
    "                  ):\n",
    "        \"\"\"Init NN\n",
    "            image_size - size of input image.\n",
    "            hidden_size - size of cnn features output\n",
    "            word_embedding - pretrained model wor word embedding\n",
    "            word_embedding_size - dimension of embedding space\n",
    "            words2ids - dictionary word -> id\n",
    "            ids2words - dictionary id -> word\n",
    "            cnn - pretrained cnn net (alexnet, vgg and other)\n",
    "            cnn_comp_features - function computes features with cnn\n",
    "            max_sentence_len - maximum sentence length when lstm stops\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM_W2V_Net, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.image_features_size = image_features_size\n",
    "        self.cnn = cnn\n",
    "     #   self.cnn_comp_features = cnn_comp_features\n",
    "        \n",
    "        self.vocab_size = len(words2ids)\n",
    "        self.word_embedding_size = word_embedding_size\n",
    "        #self.words_embedding = word_embedding\n",
    "        \n",
    "        self.words2ids = words2ids\n",
    "        self.ids2words = ids2words\n",
    "        \n",
    "#         self.sentence_end_symbol = sentence_end_symbol\n",
    "#         self.sentence_end_symbol_id = self.words2ids[self.sentence_end_symbol]\n",
    "        \n",
    "#         if sentence_end_embed is not None:\n",
    "#             self.sentence_end_embed = sentence_end_embed\n",
    "#         else:\n",
    "#             self.sentence_end_embed = word_embeding['.']\n",
    "        \n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        self.hidden_size = word_embedding_size \n",
    "        self.fc1 = nn.Sequential( nn.BatchNorm1d(self.image_features_size),\n",
    "                                  nn.Linear(self.image_features_size, int(self.image_features_size/2)),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(int(self.image_features_size/2), int(self.image_features_size/4) ),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(int(self.image_features_size/4), self.hidden_size),\n",
    "                                  nn.BatchNorm1d(self.hidden_size)\n",
    "                                )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(self.hidden_size, self.vocab_size )\n",
    "                                  ,nn.LogSoftmax()\n",
    "                                )\n",
    "        \n",
    "                               \n",
    "        self.lstm_cell = nn.LSTMCell(self.hidden_size, self.hidden_size)\n",
    "        #self.lstm = nn.LSTM(hidden_size, word_embedding_size)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def freeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # get features from images\n",
    "        batch_size = X.shape[0]\n",
    "        #print(\"1: \" ,X.shape)\n",
    "        X = self.cnn(X)\n",
    "        #X = X.cuda(gpu_device)\n",
    "        \n",
    "        #print(\"2: \",X.shape)\n",
    "        X = X.view(batch_size, self.image_features_size)\n",
    "        \n",
    "    \n",
    "        h_t = Variable(torch.zeros(batch_size, self.hidden_size), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(batch_size, self.hidden_size), requires_grad=False)\n",
    "        \n",
    "        X = self.fc1.forward(X)\n",
    "        \n",
    "        h_t, c_t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "        \n",
    "        output = []\n",
    "        for idx in range(self.max_sentence_len):\n",
    "            h_t, c_t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "            \n",
    "            r = self.fc2.forward(h_t)\n",
    "            \n",
    "            #logits = nn.LogSoftmax(r).max(2)[1]\n",
    "            \n",
    "            output.append(r)\n",
    "        \n",
    "        output = torch.stack(output, 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 500\n",
    "image_features_size = get_alexnet_features_dim(image_size)\n",
    "word_embeding_size = 1024#word_embeding.trainables.layer1_size\n",
    "sentence_end_embed = 1#word_embeding[DEF_SEND]\n",
    "cnn = models.alexnet(pretrained=True).features\n",
    "sentence_end_symbol = DEF_SEND\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmnet = LSTM_W2V_Net(image_size, image_features_size , None,\n",
    "                     word_embeding_size, words2ids, ids2words, \n",
    "                     cnn = cnn,\n",
    "                     max_sentence_len = max_sentence_len,\n",
    "                     sentence_end_embed = sentence_end_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDataLoader_2 = DataLoader(trainDataset, batch_size = 2, shuffle=True)\n",
    "for sample in trainDataLoader_2:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lstmnet.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "lstmnet.freeze_cnn()\n",
    "pred = lstmnet.forward(Variable(sample['image']))\n",
    "y = sample['anns']\n",
    "y = Variable(y)\n",
    "loss = nn.NLLLoss2d()(pred.view(pred.shape[0]*pred.shape[1], pred.shape[2]), y.view(-1))\n",
    "\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6988\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 3)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.6281 -1.6503 -1.6838  ...  -1.4406 -1.6080 -1.7250\n",
       "-1.6314 -1.6246 -1.5763  ...  -1.7085 -1.6347 -1.6576\n",
       "-1.7114 -1.5046 -1.7302  ...  -1.6352 -1.5933 -1.6092\n",
       "-1.5895 -1.6894 -1.4869  ...  -1.7164 -1.6852 -1.5047\n",
       "-1.4988 -1.5882 -1.5882  ...  -1.5728 -1.5322 -1.5650\n",
       "[torch.cuda.FloatTensor of size 5x591180 (GPU 3)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.view(5,20* 29559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.alexnet(pretrained=True).features(Variable(sample['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_'+filename)\n",
    "        \n",
    "def open_checkpoint(is_best = False, filename='checkpoint.pth.tar'):\n",
    "    if is_best:\n",
    "        filename = 'best_'+filename\n",
    "        \n",
    "    checkpoint = torch.load(filename)\n",
    "    return checkpoint\n",
    "#     best_prec1 = checkpoint['best_prec1']\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train procedure\n",
    "def train(network, train_dataloader, test_dataloader,\n",
    "          epochs, sheduler, unfreeze_cnn_epoch = None,\n",
    "          loss = nn.NLLLoss().cuda(gpu_device), optim=torch.optim.Adam ):\n",
    "    \n",
    "    if unfreeze_cnn_epoch is None:\n",
    "        unfreeze_cnn_epoch = int(0.75 * epochs)\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=0.001)\n",
    "    best_test_score = 10**6\n",
    "    \n",
    "    network.freeze_cnn()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            sheduler.step()\n",
    "            if epoch >= unfreeze_cnn_epoch:\n",
    "                network.unfreeze_cnn()\n",
    "\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                # одно изображение - одно предложение\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                \n",
    "                prediction = network(X)\n",
    "                prediction = nn.LogSoftmax(prediction).max(2)[1]\n",
    "                \n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []\n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "            is_best = test_loss_epochs[-1] < best_test_score\n",
    "            best_test_score = min(test_loss_epochs[-1], best_test_score)\n",
    "            save_checkpoint({\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': network.state_dict(),\n",
    "                            'best_test_score': best_test_score,\n",
    "                            'optimizer' : optimizer.state_dict(),\n",
    "                            }, is_best)\n",
    "                \n",
    "            \n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
