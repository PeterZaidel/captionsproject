{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import MSCOCODataset\n",
    "from torch.optim import lr_scheduler\n",
    "from autocorrect import spell\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_SEND = '<SEND>'\n",
    "DEF_START = '<START>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/home/p.zaydel/ProjectNeuralNets/coco_dataset/'\n",
    "imagesDirTrain = '{}train2017/train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017/val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}/annotations_trainval2017/annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}/annotations_trainval2017/annotations/captions_val2017.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.Compose([\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                           ])\n",
    "transform_to224 = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transform_tensor\n",
    "                                     ])\n",
    "transform_to500 = transforms.Compose([ transforms.Resize((500, 500)),\n",
    "                                      transform_tensor\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATSET_FILE = 'traindataset.tar.gz'\n",
    "TEST_DATSET_FILE = 'testdataset.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_text2words(text):\n",
    "    symbs_to_replace = ['.', ',', '/', '-', ':', '{', '}', '[', ']', ]\n",
    "    for smb in symbs_to_replace:\n",
    "        text = text.replace(smb, ' ')\n",
    "    \n",
    "    \n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    for idx in range(len(words)):\n",
    "        words[idx] = spell(words[idx])\n",
    "    \n",
    "    words = [DEF_START] + words + [DEF_SEND]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# def anns2words(anns_list):\n",
    "#     texts = []\n",
    "#     for anns in anns_list:\n",
    "#         for ann in anns['anns']:\n",
    "#             words = split_text2words(ann)\n",
    "#             texts.append(words)\n",
    "            \n",
    "#     return texts\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "def train_word_to_vec_gensim(dataset, embed_size = 300):\n",
    "    Texts = dataset.anns.values()\n",
    "    model = Word2Vec(Texts, size = embed_size)\n",
    "    return model\n",
    "\n",
    "def generate_vocab_dicts(dataset): \n",
    "    Texts = dataset.anns.values()\n",
    "    uniqwords = list(set([w for ann in Texts for w in ann]))\n",
    "    words2ids = dict(zip(uniqwords, range(len(uniqwords))) )\n",
    "    ids2words = dict(zip(range(len(uniqwords)), uniqwords ))\n",
    "    return words2ids, ids2words\n",
    "\n",
    "\n",
    "def wordslist2wordids(words, word2id, vector_length = None ):\n",
    "    if vector_length is None:\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))\n",
    "\n",
    "\n",
    "def sentence2wordids(sentence, word2id, vector_length = None):\n",
    "    \n",
    "    if vector_length is None:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))         \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "# calculates dimension of alexnet convolutions layers output \n",
    "def get_alexnet_features_dim(imsize):\n",
    "    adim = int(np.round( 3*0.01*imsize - 1))\n",
    "    return 1*256*adim*adim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_dataset(dataset, filename):\n",
    "    dataset.text_transform = split_text2words\n",
    "    dataset.preload_anotations()\n",
    "    dataset.text_transform = None\n",
    "    torch.save(dataset, filename)\n",
    "    print(\"Dataset saved in {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anns(dataset, annids, max_len, prepare = None):\n",
    "    '''\n",
    "       dataset - MSCOCODataset\n",
    "       annids -  tensor or numpy array\n",
    "       max_len - maximum len of sentence. If None computes from dataset \n",
    "       prepare - None or function to prepare each word, returns 1-dim tensor\n",
    "       \n",
    "       return Pytorch Tensor [len(annids) x max_sentence_len x prepare(word).shape[0] ]\n",
    "    '''\n",
    "    result = []\n",
    "    \n",
    "    if prepare is None:\n",
    "        prepare = lambda w: word_embeding[w]\n",
    "    \n",
    "    for i in range(annids.shape[0]):\n",
    "        words = dataset.get_ann(annids[i])\n",
    "        ann_res = []\n",
    "        \n",
    "        for idx in range(max_len):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = DEF_SEND\n",
    "                \n",
    "            ann_res.append(prepare(w))\n",
    "        ann_res = torch.from_numpy(np.array(ann_res)).float()\n",
    "        result.append(ann_res)\n",
    "        \n",
    "    return torch.stack(result)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train dataset...\n",
      "train dataset loaded!\n",
      "loading test dataset...\n",
      "test dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(TRAIN_DATSET_FILE):\n",
    "    print(\"loading train dataset...\")\n",
    "    trainDataset = torch.load(TRAIN_DATSET_FILE)\n",
    "    print('train dataset loaded!')\n",
    "else:\n",
    "    trainDataset = MSCOCODataset(annTrainFile,imagesDirTrain, transform = transform_to224, mode='pic2rand')\n",
    "    save_prepared_dataset(trainDataset, TRAIN_DATSET_FILE)\n",
    "    \n",
    "if os.path.exists(TEST_DATSET_FILE):\n",
    "    print(\"loading test dataset...\")\n",
    "    testDataset = torch.load(TEST_DATSET_FILE)\n",
    "    print('test dataset loaded!')\n",
    "else:\n",
    "    testDataset = MSCOCODataset(annValFile,imagesDirVal, transform = transform_to224, mode='pic2rand')\n",
    "    save_prepared_dataset(testDataset, TEST_DATSET_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.transform = transform_to224\n",
    "testDataset.transform = transform_to224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_transform = lambda text: sentence2wordids(text, words2ids, vector_length = 20)\n",
    "# trainDataset.text_transform = text_transform\n",
    "# testDataset.text_transform = text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainAnnCaps = [ann['caption'] for ann in trainDataset.coco.loadAnns(trainDataset.coco.getAnnIds())]\n",
    "\n",
    "# trainAnns = trainDataset.anns.values()\n",
    "# trainTexts = anns2words(trainAnns)\n",
    "# sent_lengths = np.array([len(ann) for ann in trainTexts])\n",
    "# print(\"max sent id\", sent_lengths.argmax())\n",
    "# print('max len',np.max(sent_lengths))\n",
    "# plt.plot(np.unique(sent_lengths), np.bincount(sent_lengths)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testAnns = testDataset.anns.values()\n",
    "# testTexts = anns2words(testAnns)\n",
    "# test_sent_lengths = np.array([len(ann) for ann in testTexts])\n",
    "# print(\"max sent id\", test_sent_lengths.argmax())\n",
    "# print('max len',np.max(test_sent_lengths))\n",
    "# test_bin_count = np.bincount(test_sent_lengths)\n",
    "# plt.plot(np.unique(test_sent_lengths), test_bin_count[test_bin_count > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary......\n",
      "loading dictionary\n",
      "dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Creating dictionary......\")\n",
    "if os.path.exists('dictionaries.tar.gz'):\n",
    "    print(\"loading dictionary\")\n",
    "    dic_state = torch.load('dictionaries.tar.gz')\n",
    "    words2ids = dic_state['words2ids']\n",
    "    ids2words = dic_state['ids2words']\n",
    "    print(\"dictionary loaded\")\n",
    "else:\n",
    "    words2ids, ids2words  = generate_vocab_dicts(trainDataset)\n",
    "    print(\"saving dictionary\")\n",
    "    torch.save({'words2ids': words2ids, 'ids2words': ids2words }, 'dictionaries.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14388"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids[DEF_START]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE google word embeddings pretrined\n",
    "\n",
    "#import gensim\n",
    "#google_word_embeding = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorchEmbed_from_pretrained(embeddings, freeze=True):\n",
    "    rows, cols = embeddings.shape\n",
    "    embedding = torch.nn.Embedding(num_embeddings=rows, embedding_dim=cols)\n",
    "    embedding.weight = torch.nn.Parameter(embeddings)\n",
    "    embedding.weight.requires_grad = not freeze\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # additional train on dataset\n",
    "\n",
    "# uniq_words = []\n",
    "# for l in trainDataset.anns.values():\n",
    "#     for w in l:\n",
    "#         uniq_words.append(w)\n",
    "# uniq_words = set(uniq_words)\n",
    "\n",
    "# problem_words = []\n",
    "# for w in uniq_words:\n",
    "#     try:\n",
    "#         emb = google_word_embeding[w]\n",
    "#     except:\n",
    "#         problem_words.append(w)\n",
    "# problem_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(problem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading words embedding\n",
      "words embedding loaded\n"
     ]
    }
   ],
   "source": [
    "# MY WORD EMBEDDINGS\n",
    "\n",
    "import os\n",
    "\n",
    "WORD_EMBED_FILE = 'word_embeding.tar.gz'\n",
    "if os.path.exists(WORD_EMBED_FILE):\n",
    "    print(\"loading words embedding\")\n",
    "    word_embeding = torch.load(WORD_EMBED_FILE)\n",
    "    print(\"words embedding loaded\")\n",
    "else:\n",
    "    print(\"creating words embedding......\")\n",
    "    word_embeding = train_word_to_vec_gensim(trainDataset, embed_size = 300 )\n",
    "    print(\"saving words embedding\")\n",
    "    torch.save(word_embeding, WORD_EMBED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = google_word_embeding['cat'] + google_word_embeding['kitten']\n",
    "# google_word_embeding.similar_by_vector(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anns = trainDataset.anns.values()\n",
    "# Texts = anns2words(Anns, DEF_SEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# problem_words = []\n",
    "# uniq_words = set(words2ids.keys())\n",
    "# for word in tqdm.tqdm_notebook(uniq_words):\n",
    "#     try:\n",
    "#         emb = google_word_embeding[spell(word)]\n",
    "#     except:\n",
    "#         #print(\"w:{}  corrected:{}\".format(word, spell(word)))\n",
    "#         problem_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(problem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sentence2wordids(Anns[0]['anns'][3], words2ids,  vector_length = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainDataset, batch_size = 64, shuffle=True)\n",
    "testDataLoader = DataLoader(testDataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = word_embeding['.']\n",
    "# print(vec)\n",
    "# word_embeding.wv.similar_by_vector(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(words2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_t = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "# c_t = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "        \n",
    "# prevWord = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "# X = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "\n",
    "# X = torch.cat([X, prevWord])\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3\n",
       " 1  2  3\n",
       "[torch.LongTensor of size 2x3]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.from_numpy(np.array([1, 2, 3])), torch.from_numpy(np.array([1, 2, 3]))],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "\n",
      " 1  2  3  4\n",
      " 1  2  3  4\n",
      " 1  2  3  4\n",
      " 1  2  3  4\n",
      " 1  2  3  4\n",
      "[torch.FloatTensor of size 5x4]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     1     2     3\n",
       "    0     0     0     0     0     0     0     0     0     0     1     2     3\n",
       "    0     0     0     0     0     0     0     0     0     0     1     2     3\n",
       "    0     0     0     0     0     0     0     0     0     0     1     2     3\n",
       "    0     0     0     0     0     0     0     0     0     0     1     2     3\n",
       "\n",
       "Columns 13 to 13 \n",
       "    4\n",
       "    4\n",
       "    4\n",
       "    4\n",
       "    4\n",
       "[torch.FloatTensor of size 5x14]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = torch.zeros(5, 10)\n",
    "print(wt)\n",
    "\n",
    "tt = torch.from_numpy(np.array([1.0, 2.0, 3.0, 4.0])).float()\n",
    "tt = tt.repeat(5, 1)\n",
    "print(tt)\n",
    "\n",
    "torch.cat([wt, tt], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(print lstm_input)? (<ipython-input-123-dc98c51dc83e>, line 119)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-123-dc98c51dc83e>\"\u001b[0;36m, line \u001b[0;32m119\u001b[0m\n\u001b[0;31m    print lstm_input\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(print lstm_input)?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LSTM_W2V_Net(nn.Module):\n",
    "\n",
    "    def __init__(self,  image_size, image_features_size, word_embedding, words2ids, ids2words,\n",
    "                 lstm_hidden_size = 4096,\n",
    "                 word_embedding_size = 300, \n",
    "                 cnn = models.alexnet(pretrained=True).features,\n",
    "                 start_symbol = DEF_START,\n",
    "                 end_symbol = DEF_SEND\n",
    "              #   cnn_comp_features = lambda cnn, x: cnn.features(x),\n",
    "              #   max_sentence_len = 20,\n",
    "              #   sentence_end_embed = None,\n",
    "             #  sentence_end_symbol = '.'\n",
    "                  ):\n",
    "        \"\"\"Init NN\n",
    "            image_size - size of input image.\n",
    "            lstm_hidden_size - size of cnn features output\n",
    "            image_features_size - size of image features vector\n",
    "            word_embedding - pretrained word embedding model\n",
    "            words2ids - dictionary word -> id\n",
    "            ids2words - dictionary id -> word\n",
    "            cnn - pretrained cnn net (alexnet, vgg and other)\n",
    "            start_symbol - symbol starting sequence\n",
    "            end_symbol - symbol ending sequence\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM_W2V_Net, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.image_features_size = image_features_size\n",
    "        self.cnn = cnn\n",
    "     #   self.cnn_comp_features = cnn_comp_features\n",
    "        \n",
    "        self.vocab_size = len(words2ids)\n",
    "        self.word_embedding_size = word_embedding_size\n",
    "        self.word_embedding = word_embedding\n",
    "        \n",
    "        self.words2ids = words2ids\n",
    "        self.ids2words = ids2words\n",
    "        \n",
    "        self.start_symbol = start_symbol\n",
    "        self.start_symbol_embed = torch.from_numpy(self.word_embedding[self.start_symbol])\n",
    "        \n",
    "        self.end_symbol = end_symbol\n",
    "        self.end_symbol_embed = torch.from_numpy(self.word_embedding[self.end_symbol])\n",
    "        \n",
    "#         self.sentence_end_symbol = sentence_end_symbol\n",
    "#         self.sentence_end_symbol_id = self.words2ids[self.sentence_end_symbol]\n",
    "        \n",
    "#         if sentence_end_embed is not None:\n",
    "#             self.sentence_end_embed = sentence_end_embed\n",
    "#         else:\n",
    "#             self.sentence_end_embed = word_embeding['.']\n",
    "        \n",
    "        #self.max_sentence_len = max_sentence_len\n",
    "        \n",
    "        \n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Sequential( nn.BatchNorm1d(self.image_features_size),\n",
    "                                  nn.Linear(self.image_features_size, int(self.image_features_size/2)),\n",
    "                                  nn.Dropout(0.001), \n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(int(self.image_features_size/2), int(self.image_features_size/4) ),\n",
    "                                  nn.Dropout(0.001),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(int(self.image_features_size/4), self.lstm_hidden_size),\n",
    "                                  nn.BatchNorm1d(self.lstm_hidden_size)\n",
    "                                )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(#nn.Linear(self.lstm_hidden_size, self.vocab_size),\n",
    "                                  nn.LogSoftmax()\n",
    "                                )\n",
    "        \n",
    "                               \n",
    "        self.lstm_cell = nn.LSTMCell(self.lstm_hidden_size + self.word_embedding_size, self.vocab_size)\n",
    "        \n",
    "        #self.lstm = nn.LSTM(self.lstm_hidden_size , word_embedding_size)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def freeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    def ids_to_embed(self, word_ids):\n",
    "        result = []\n",
    "        for i in range(word_ids.shape[0]):\n",
    "            w = self.ids2words[word_ids[i]]\n",
    "            emb = torch.from_numpy(self.word_embedding[w]).float()\n",
    "            result.append(emb)\n",
    "            \n",
    "        return torch.stack(result, 1)\n",
    "        \n",
    "            \n",
    "            \n",
    "    def forward(self, X, max_sentence_len):\n",
    "        batch_size = X.shape[0]\n",
    "        X = self.cnn(X)\n",
    "        X = X.view(batch_size, self.image_features_size)\n",
    "        \n",
    "        # prevWord = START_SYMBOL\n",
    "        prevWord = Variable(self.start_symbol_embed.repeat(batch_size, 1), requires_grad=False)\n",
    "        \n",
    "\n",
    "        \n",
    "        lstm_input = torch.cat([X, prevWord], dim = 1)\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        result.append(prevWord)\n",
    "        \n",
    "        h_t = Variable(torch.zeros(batch_size, self.lstm_hidden_size), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(batch_size, self.lstm_hidden_size), requires_grad=False)\n",
    "        \n",
    "        print(lstm_input)\n",
    "        \n",
    "        for idx in range(max_sentence_len):\n",
    "            h_t, c_t = self.lstm_cell.forward(lstm_input, (h_t, c_t))\n",
    "            probs = self.fc2.forward(h_t)\n",
    "            top_word_ids = probs.max(2)[1]\n",
    "            embeds = self.ids_to_embed(top_word_ids)\n",
    "            \n",
    "            lstm_input = torch.cat([X, prevWord], dim = 1)\n",
    "            result.append(probs)\n",
    "        \n",
    "        return torch.stack(result, 1)\n",
    "        \n",
    "    \n",
    "#     def forward_old(self, X):\n",
    "#         # get features from images\n",
    "#         batch_size = X.shape[0]\n",
    "#         #print(\"1: \" ,X.shape)\n",
    "#         X = self.cnn(X)\n",
    "#         #X = X.cuda(gpu_device)\n",
    "        \n",
    "#         #print(\"2: \",X.shape)\n",
    "#         X = X.view(batch_size, self.image_features_size)\n",
    "        \n",
    "    \n",
    "#         h_t = Variable(torch.zeros(batch_size, self.lstm_hidden_size), requires_grad=False)\n",
    "#         c_t = Variable(torch.zeros(batch_size, self.lstm_hidden_size), requires_grad=False)\n",
    "        \n",
    "#         prevWord = Variable(torch.zeros(batch_size, self.lstm_hidden_size), requires_grad=False)\n",
    "        \n",
    "#         X = self.fc1.forward(X)\n",
    "        \n",
    "#         X = torch.cat([X, prevWord])\n",
    "        \n",
    "#         output, hidden = self.lstm.forward()\n",
    "        \n",
    "#         h_t, c_t = \n",
    "        \n",
    "#         h_t, c_t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "        \n",
    "#         output = []\n",
    "#         for idx in range(self.max_sentence_len):\n",
    "#             h_t, c _t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "            \n",
    "#             r = self.fc2.forward(h_t)\n",
    "            \n",
    "#             #logits = nn.LogSoftmax(r).max(2)[1]\n",
    "            \n",
    "#             output.append(r)\n",
    "        \n",
    "#         output = torch.stack(output, 1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size, image_features_size, word_embedding, words2ids, ids2words,\n",
    "#                  lstm_hidden_size = 4096,\n",
    "#                  word_embedding_size = 300, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#word_embeding_size = 1024#word_embeding.trainables.layer1_size\n",
    "#sentence_end_embed = 1#word_embeding[DEF_SEND]\n",
    "# cnn = models.alexnet(pretrained=True).features\n",
    "#sentence_end_symbol = DEF_SEND\n",
    "#max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n",
      "  import sys\n",
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "image_features_size = get_alexnet_features_dim(image_size)\n",
    "\n",
    "lstmnet = LSTM_W2V_Net(image_size, image_features_size , \n",
    "                       word_embeding, words2ids, ids2words, \n",
    "                       lstm_hidden_size = 4096, \n",
    "                       word_embedding_size= word_embeding.layer1_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model  = models.alexnet(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  0.0000\n",
       "  0.0000\n",
       "  3.0473\n",
       "   ⋮    \n",
       "  0.0000\n",
       "  0.0000\n",
       "  0.0000\n",
       "[torch.FloatTensor of size 9216]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model(Variable(trainDataset[0]['image'].unsqueeze(0))).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDataLoader_2 = DataLoader(trainDataset, batch_size = 2, shuffle=True)\n",
    "for sample in trainDataLoader_2:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['ann_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_ids = load_anns(trainDataset, sample['anns'], sample['ann_len'].max(), prepare=lambda w: words2ids[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  4516\n",
       "  6507\n",
       "  9543\n",
       " 19828\n",
       " 11328\n",
       " 16342\n",
       " 17629\n",
       " 15361\n",
       " 20535\n",
       " 15190\n",
       "  4602\n",
       " 16342\n",
       "  8273\n",
       "  7411\n",
       " 20238\n",
       " 16048\n",
       "[torch.FloatTensor of size 16]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b9d7585a9a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlstmnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstmnet' is not defined"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(lstmnet.parameters(), lr=0.001)\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "lstmnet.freeze_cnn()\n",
    "\n",
    "X = sample['image']\n",
    "X = Variable(X)\n",
    "\n",
    "ann_ids = sample['anns']\n",
    "\n",
    "batch_size = X.shape[0]\n",
    "max_len = sample['ann_len'].max()\n",
    "\n",
    "y = load_anns(trainDataset, ann_ids, max_len, prepare=lambda w: words2ids[w])\n",
    "\n",
    "pred = lstmnet.forward(X, max_len)\n",
    "pred\n",
    "\n",
    "#loss = nn.NLLLoss2d()(pred.view(pred.shape[0]*pred.shape[1], pred.shape[2]), y.view(-1))\n",
    "\n",
    "\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6988\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 3)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.view(5,20* 29559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.alexnet(pretrained=True).features(Variable(sample['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_'+filename)\n",
    "        \n",
    "def open_checkpoint(is_best = False, filename='checkpoint.pth.tar'):\n",
    "    if is_best:\n",
    "        filename = 'best_'+filename\n",
    "        \n",
    "    checkpoint = torch.load(filename)\n",
    "    return checkpoint\n",
    "#     best_prec1 = checkpoint['best_prec1']\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train procedure\n",
    "def train(network, train_dataloader, test_dataloader,\n",
    "          epochs,  unfreeze_cnn_epoch = None,\n",
    "          loss = nn.NLLLoss().cuda(gpu_device), optim=torch.optim.Adam ):\n",
    "    \n",
    "    if unfreeze_cnn_epoch is None:\n",
    "        unfreeze_cnn_epoch = int(0.75 * epochs)\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=0.001)\n",
    "    best_test_score = 10**6\n",
    "    \n",
    "    network.freeze_cnn()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            sheduler.step()\n",
    "            if epoch >= unfreeze_cnn_epoch:\n",
    "                network.unfreeze_cnn()\n",
    "\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                y = \n",
    "                \n",
    "                # одно изображение - одно предложение\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                \n",
    "                prediction = network(X)\n",
    "                prediction = nn.LogSoftmax(prediction).max(2)[1]\n",
    "                \n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []\n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "            is_best = test_loss_epochs[-1] < best_test_score\n",
    "            best_test_score = min(test_loss_epochs[-1], best_test_score)\n",
    "            save_checkpoint({\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': network.state_dict(),\n",
    "                            'best_test_score': best_test_score,\n",
    "                            'optimizer' : optimizer.state_dict(),\n",
    "                            }, is_best)\n",
    "                \n",
    "            \n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
