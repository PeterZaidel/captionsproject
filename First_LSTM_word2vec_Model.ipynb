{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import MSCOCODataset\n",
    "from torch.optim import lr_scheduler\n",
    "from autocorrect import spell\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_SEND = '<SEND>'\n",
    "DEF_START = '<START>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/home/p.zaydel/ProjectNeuralNets/coco_dataset/'\n",
    "imagesDirTrain = '{}train2017/train2017'.format(dataDir)\n",
    "imagesDirVal = '{}val2017/val2017'.format(dataDir)\n",
    "\n",
    "annTrainFile = '{}/annotations_trainval2017/annotations/captions_train2017.json'.format(dataDir)\n",
    "annValFile = '{}/annotations_trainval2017/annotations/captions_val2017.json'.format(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.Compose([\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                           ])\n",
    "transform_to224 = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transform_tensor\n",
    "                                     ])\n",
    "transform_to500 = transforms.Compose([ transforms.Resize((500, 500)),\n",
    "                                      transform_tensor\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATSET_FILE = 'traindataset.tar.gz'\n",
    "TEST_DATSET_FILE = 'testdataset.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_text2words(text):\n",
    "    symbs_to_replace = ['.', ',', '/', '-', ':', '{', '}', '[', ']', ]\n",
    "    for smb in symbs_to_replace:\n",
    "        text = text.replace(smb, ' ')\n",
    "    \n",
    "    \n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    for idx in range(len(words)):\n",
    "        words[idx] = spell(words[idx])\n",
    "    \n",
    "    words = [DEF_START] + words + [DEF_SEND]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# def anns2words(anns_list):\n",
    "#     texts = []\n",
    "#     for anns in anns_list:\n",
    "#         for ann in anns['anns']:\n",
    "#             words = split_text2words(ann)\n",
    "#             texts.append(words)\n",
    "            \n",
    "#     return texts\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "def train_word_to_vec_gensim(dataset, embed_size = 4096):\n",
    "    Texts = dataset.anns.values()\n",
    "    model = Word2Vec(Texts, size = embed_size)\n",
    "    return model\n",
    "\n",
    "def generate_vocab_dicts(dataset): \n",
    "    Texts = dataset.anns.values()\n",
    "    uniqwords = list(set([w for ann in Texts for w in ann]))\n",
    "    words2ids = dict(zip(uniqwords, range(len(uniqwords))) )\n",
    "    ids2words = dict(zip(range(len(uniqwords)), uniqwords ))\n",
    "    return words2ids, ids2words\n",
    "\n",
    "\n",
    "def wordslist2wordids(words, word2id, vector_length = None ):\n",
    "    if vector_length is None:\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))\n",
    "\n",
    "\n",
    "def sentence2wordids(sentence, word2id, vector_length = None):\n",
    "    \n",
    "    if vector_length is None:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = [word2id[w] for w in words]\n",
    "        \n",
    "    else:\n",
    "        words = split_text2words(sentence)\n",
    "        word_ids = []\n",
    "        for idx in range(vector_length):\n",
    "            if idx < len(words):\n",
    "                w = words[idx]\n",
    "            else:\n",
    "                w = end_word\n",
    "                \n",
    "            word_ids.append(word2id[w])\n",
    "        \n",
    "        if word_ids[-1] != word2id[DEF_SEND]:\n",
    "            word_ids[-1] = word2id[DEF_SEND]\n",
    "        \n",
    "    return torch.from_numpy(np.array(word_ids).astype(np.int))         \n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "# calculates dimension of alexnet convolutions layers output \n",
    "def get_alexnet_features_dim(imsize):\n",
    "    adim = int(np.round( 3*0.01*imsize - 1))\n",
    "    return 1*256*adim*adim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_dataset(dataset, filename):\n",
    "    dataset.text_transform = split_text2words\n",
    "    dataset.preload_anotations()\n",
    "    dataset.text_transform = None\n",
    "    torch.save(dataset, filename)\n",
    "    print(\"Dataset saved in {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_DATSET_FILE):\n",
    "    print(\"loading train dataset...\")\n",
    "    trainDataset = torch.load(TRAIN_DATSET_FILE)\n",
    "    print('train dataset loaded!')\n",
    "else:\n",
    "    trainDataset = MSCOCODataset(annTrainFile,imagesDirTrain, transform = transform_to500, mode='pic2rand')\n",
    "    save_prepared_dataset(trainDataset, TRAIN_DATSET_FILE)\n",
    "    \n",
    "if os.path.exists(TEST_DATSET_FILE):\n",
    "    print(\"loading test dataset...\")\n",
    "    trainDataset = torch.load(TEST_DATSET_FILE)\n",
    "    print('test dataset loaded!')\n",
    "else:\n",
    "    testDataset = MSCOCODataset(annValFile,imagesDirVal, transform = transform_to500, mode='pic2rand')\n",
    "    save_prepared_dataset(testDataset, TEST_DATSET_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = lambda text: sentence2wordids(text, words2ids, vector_length = 20)\n",
    "trainDataset.text_transform = text_transform\n",
    "testDataset.text_transform = text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainAnnCaps = [ann['caption'] for ann in trainDataset.coco.loadAnns(trainDataset.coco.getAnnIds())]\n",
    "\n",
    "# trainAnns = trainDataset.anns.values()\n",
    "# trainTexts = anns2words(trainAnns)\n",
    "# sent_lengths = np.array([len(ann) for ann in trainTexts])\n",
    "# print(\"max sent id\", sent_lengths.argmax())\n",
    "# print('max len',np.max(sent_lengths))\n",
    "# plt.plot(np.unique(sent_lengths), np.bincount(sent_lengths)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testAnns = testDataset.anns.values()\n",
    "# testTexts = anns2words(testAnns)\n",
    "# test_sent_lengths = np.array([len(ann) for ann in testTexts])\n",
    "# print(\"max sent id\", test_sent_lengths.argmax())\n",
    "# print('max len',np.max(test_sent_lengths))\n",
    "# test_bin_count = np.bincount(test_sent_lengths)\n",
    "# plt.plot(np.unique(test_sent_lengths), test_bin_count[test_bin_count > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary......\n",
      "loading dictionary\n",
      "dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Creating dictionary......\")\n",
    "if os.path.exists('dictionaries.tar.gz'):\n",
    "    print(\"loading dictionary\")\n",
    "    dic_state = torch.load('dictionaries.tar.gz')\n",
    "    words2ids = dic_state['words2ids']\n",
    "    ids2words = dic_state['ids2words']\n",
    "    print(\"dictionary loaded\")\n",
    "else:\n",
    "    words2ids, ids2words  = generate_vocab_dicts(trainDataset)\n",
    "    print(\"saving dictionary\")\n",
    "    torch.save({'words2ids': words2ids, 'ids2words': ids2words }, 'dictionaries.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE google word embeddings pretrined\n",
    "\n",
    "import gensim\n",
    "google_word_embeding = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorchEmbed_from_pretrained(embeddings, freeze=True):\n",
    "    rows, cols = embeddings.shape\n",
    "    embedding = torch.nn.Embedding(num_embeddings=rows, embedding_dim=cols)\n",
    "    embedding.weight = torch.nn.Parameter(embeddings)\n",
    "    embedding.weight.requires_grad = not freeze\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # additional train on dataset\n",
    "\n",
    "# uniq_words = []\n",
    "# for l in trainDataset.anns.values():\n",
    "#     for w in l:\n",
    "#         uniq_words.append(w)\n",
    "# uniq_words = set(uniq_words)\n",
    "\n",
    "# problem_words = []\n",
    "# for w in uniq_words:\n",
    "#     try:\n",
    "#         emb = google_word_embeding[w]\n",
    "#     except:\n",
    "#         problem_words.append(w)\n",
    "# problem_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(problem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating words embedding......\n",
      "saving words embedding\n"
     ]
    }
   ],
   "source": [
    "# MY WORD EMBEDDINGS\n",
    "\n",
    "import os\n",
    "\n",
    "WORD_EMBED_FILE = 'word_embeding.tar.gz'\n",
    "if os.path.exists(WORD_EMBED_FILE):\n",
    "    print(\"loading words embedding\")\n",
    "    word_embeding = torch.load(WORD_EMBED_FILE)\n",
    "    print(\"words embedding loaded\")\n",
    "else:\n",
    "    print(\"creating words embedding......\")\n",
    "    word_embeding = train_word_to_vec_gensim(trainDataset, embed_size = 300 )\n",
    "    print(\"saving words embedding\")\n",
    "    torch.save(word_embeding, WORD_EMBED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kitten', 0.9413747787475586),\n",
       " ('cat', 0.9272116422653198),\n",
       " ('puppy', 0.7981034517288208),\n",
       " ('cats', 0.7747195959091187),\n",
       " ('pup', 0.7682398557662964),\n",
       " ('dog', 0.7606886625289917),\n",
       " ('kittens', 0.757416844367981),\n",
       " ('feline', 0.7283889651298523),\n",
       " ('puppies', 0.7263944149017334),\n",
       " ('beagle', 0.7203243970870972)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = google_word_embeding['cat'] + google_word_embeding['kitten']\n",
    "google_word_embeding.similar_by_vector(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9809730648994446),\n",
       " ('kitten', 0.9387789964675903),\n",
       " ('puppy', 0.7535291314125061),\n",
       " ('dog', 0.6668509244918823),\n",
       " ('kitty', 0.6435607075691223),\n",
       " ('cats', 0.6045502424240112),\n",
       " ('cay', 0.6024852395057678),\n",
       " ('pillow', 0.5992676019668579),\n",
       " ('bird', 0.5968787670135498),\n",
       " ('bear', 0.5537928938865662)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = word_embeding['cat'] + word_embeding['kitten']\n",
    "word_embeding.similar_by_vector(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Anns = trainDataset.anns.values()\n",
    "# Texts = anns2words(Anns, DEF_SEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# problem_words = []\n",
    "# uniq_words = set(words2ids.keys())\n",
    "# for word in tqdm.tqdm_notebook(uniq_words):\n",
    "#     try:\n",
    "#         emb = google_word_embeding[spell(word)]\n",
    "#     except:\n",
    "#         #print(\"w:{}  corrected:{}\".format(word, spell(word)))\n",
    "#         problem_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(problem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sentence2wordids(Anns[0]['anns'][3], words2ids,  vector_length = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainDataset, batch_size = 64, shuffle=True)\n",
    "testDataLoader = DataLoader(testDataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in trainDataLoader:\n",
    "#     break\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = word_embeding['.']\n",
    "# print(vec)\n",
    "# word_embeding.wv.similar_by_vector(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(words2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_t = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "# c_t = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "        \n",
    "# prevWord = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "# X = Variable(torch.zeros(5, 10), requires_grad=False)\n",
    "\n",
    "# X = torch.cat([X, prevWord])\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM_W2V_Net(nn.Module):\n",
    "\n",
    "    def __init__(self,  image_size, image_features_size, word_embedding, \n",
    "                 word_embedding_size, words2ids, ids2words,\n",
    "                 \n",
    "                 cnn = models.alexnet(pretrained=True).features, \n",
    "              #   cnn_comp_features = lambda cnn, x: cnn.features(x),\n",
    "                 max_sentence_len = 20,\n",
    "                 sentence_end_embed = None,\n",
    "                 sentence_end_symbol = '.'\n",
    "                  ):\n",
    "        \"\"\"Init NN\n",
    "            image_size - size of input image.\n",
    "            hidden_size - size of cnn features output\n",
    "            word_embedding - pretrained model wor word embedding\n",
    "            word_embedding_size - dimension of embedding space\n",
    "            words2ids - dictionary word -> id\n",
    "            ids2words - dictionary id -> word\n",
    "            cnn - pretrained cnn net (alexnet, vgg and other)\n",
    "            cnn_comp_features - function computes features with cnn\n",
    "            max_sentence_len - maximum sentence length when lstm stops\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM_W2V_Net, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.image_features_size = image_features_size\n",
    "        self.cnn = cnn\n",
    "     #   self.cnn_comp_features = cnn_comp_features\n",
    "        \n",
    "        self.vocab_size = len(words2ids)\n",
    "        self.word_embedding_size = word_embedding_size\n",
    "        #self.words_embedding = word_embedding\n",
    "        \n",
    "        self.words2ids = words2ids\n",
    "        self.ids2words = ids2words\n",
    "        \n",
    "#         self.sentence_end_symbol = sentence_end_symbol\n",
    "#         self.sentence_end_symbol_id = self.words2ids[self.sentence_end_symbol]\n",
    "        \n",
    "#         if sentence_end_embed is not None:\n",
    "#             self.sentence_end_embed = sentence_end_embed\n",
    "#         else:\n",
    "#             self.sentence_end_embed = word_embeding['.']\n",
    "        \n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        self.hidden_size = word_embedding_size \n",
    "        self.fc1 = nn.Sequential( nn.BatchNorm1d(self.image_features_size),\n",
    "                                  nn.Linear(self.image_features_size, int(self.image_features_size/2)),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(int(self.image_features_size/2), int(self.image_features_size/4) ),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(int(self.image_features_size/4), self.hidden_size),\n",
    "                                  nn.BatchNorm1d(self.hidden_size)\n",
    "                                )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(self.hidden_size, self.vocab_size )\n",
    "                                  ,nn.LogSoftmax()\n",
    "                                )\n",
    "        \n",
    "                               \n",
    "        self.lstm_cell = nn.LSTMCell(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_size, word_embedding_size)\n",
    "    \n",
    "        \n",
    "    \n",
    "    def freeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_cnn(self):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # get features from images\n",
    "        batch_size = X.shape[0]\n",
    "        #print(\"1: \" ,X.shape)\n",
    "        X = self.cnn(X)\n",
    "        #X = X.cuda(gpu_device)\n",
    "        \n",
    "        #print(\"2: \",X.shape)\n",
    "        X = X.view(batch_size, self.image_features_size)\n",
    "        \n",
    "    \n",
    "        h_t = Variable(torch.zeros(batch_size, self.hidden_size), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(batch_size, self.hidden_size), requires_grad=False)\n",
    "        \n",
    "        prevWord = Variable(torch.zeros(batch_size, self.hidden_size), requires_grad=False)\n",
    "        \n",
    "        X = self.fc1.forward(X)\n",
    "        \n",
    "        X = torch.cat([X, prevWord])\n",
    "        \n",
    "        output, hidden = self.lstm.forward()\n",
    "        \n",
    "        h_t, c_t = \n",
    "        \n",
    "        h_t, c_t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "        \n",
    "        output = []\n",
    "        for idx in range(self.max_sentence_len):\n",
    "            h_t, c _t = self.lstm_cell.forward(X, (h_t, c_t))\n",
    "            \n",
    "            r = self.fc2.forward(h_t)\n",
    "            \n",
    "            #logits = nn.LogSoftmax(r).max(2)[1]\n",
    "            \n",
    "            output.append(r)\n",
    "        \n",
    "        output = torch.stack(output, 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 500\n",
    "image_features_size = get_alexnet_features_dim(image_size)\n",
    "word_embeding_size = 1024#word_embeding.trainables.layer1_size\n",
    "sentence_end_embed = 1#word_embeding[DEF_SEND]\n",
    "cnn = models.alexnet(pretrained=True).features\n",
    "sentence_end_symbol = DEF_SEND\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmnet = LSTM_W2V_Net(image_size, image_features_size , None,\n",
    "                     word_embeding_size, words2ids, ids2words, \n",
    "                     cnn = cnn,\n",
    "                     max_sentence_len = max_sentence_len,\n",
    "                     sentence_end_embed = sentence_end_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainDataLoader_2 = DataLoader(trainDataset, batch_size = 2, shuffle=True)\n",
    "# for sample in trainDataLoader_2:\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(lstmnet.parameters(), lr=0.001)\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.zaydel/conda3/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "# lstmnet.freeze_cnn()\n",
    "# pred = lstmnet.forward(Variable(sample['image']))\n",
    "# y = sample['anns']\n",
    "# y = Variable(y)\n",
    "# loss = nn.NLLLoss2d()(pred.view(pred.shape[0]*pred.shape[1], pred.shape[2]), y.view(-1))\n",
    "\n",
    "\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6988\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 3)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.view(5,20* 29559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.alexnet(pretrained=True).features(Variable(sample['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_'+filename)\n",
    "        \n",
    "def open_checkpoint(is_best = False, filename='checkpoint.pth.tar'):\n",
    "    if is_best:\n",
    "        filename = 'best_'+filename\n",
    "        \n",
    "    checkpoint = torch.load(filename)\n",
    "    return checkpoint\n",
    "#     best_prec1 = checkpoint['best_prec1']\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train procedure\n",
    "def train(network, train_dataloader, test_dataloader,\n",
    "          epochs, sheduler, unfreeze_cnn_epoch = None,\n",
    "          loss = nn.NLLLoss().cuda(gpu_device), optim=torch.optim.Adam ):\n",
    "    \n",
    "    if unfreeze_cnn_epoch is None:\n",
    "        unfreeze_cnn_epoch = int(0.75 * epochs)\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=0.001)\n",
    "    best_test_score = 10**6\n",
    "    \n",
    "    network.freeze_cnn()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            sheduler.step()\n",
    "            if epoch >= unfreeze_cnn_epoch:\n",
    "                network.unfreeze_cnn()\n",
    "\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for sample in train_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                y = \n",
    "                \n",
    "                # одно изображение - одно предложение\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                \n",
    "                prediction = network(X)\n",
    "                prediction = nn.LogSoftmax(prediction).max(2)[1]\n",
    "                \n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []\n",
    "            for sample in test_dataloader:\n",
    "                X = sample['image']\n",
    "                X = Variable(X)\n",
    "                y = sample['anns']\n",
    "                \n",
    "                y = Variable(y)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0])\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "            is_best = test_loss_epochs[-1] < best_test_score\n",
    "            best_test_score = min(test_loss_epochs[-1], best_test_score)\n",
    "            save_checkpoint({\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': network.state_dict(),\n",
    "                            'best_test_score': best_test_score,\n",
    "                            'optimizer' : optimizer.state_dict(),\n",
    "                            }, is_best)\n",
    "                \n",
    "            \n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) MSE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
